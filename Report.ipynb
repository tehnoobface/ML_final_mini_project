{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Report: BBC Document Analysis\n",
    "\n",
    "By: Maclean Sherren\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In my research into language models and the various pros and cons to each, I discovered a dataset known as the Google News dataset. Along with this dataset comes prre-trained vectors that contain 300-dimensional vectors for 3 million words and was trained on 100 billion words all related to large media news.\n",
    "\n",
    "This report aims to explore the effectiveness of Google's pretrained language vectorization model when compared to regular data vectorization. First, I will explore the data, highlighting any anomalies or noteworthy features. Following, the data will be ran through a regular word vectorization model called Word2Vec, a similar model to TP-IDF. The transformed data will then be split and trained on two machine learning models - a linear model and a random forest. This will be repeated but with the Google News vectorization model instead of the Word2Vec model. Finally, the results of each vectorization model will be compared to help better understand the strengths and weaknesses of each model.\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "## Exploratory Data Analysis and Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# !! Packages like gensim and sklearn may need to be installed using conda or pip to successfully run this cell\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "from gensim import utils\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "bbc_data = pd.read_csv('bbc_data.csv')\n",
    "\n",
    "bbc_data.head()\n",
    "\n",
    "# Number of documents in each label\n",
    "print(bbc_data['labels'].value_counts())\n",
    "\n",
    "# The number of documents in each label plotted\n",
    "\n",
    "bbc_data_copy = bbc_data.copy()\n",
    "bbc_data_copy['doc_length'] = bbc_data_copy['data'].apply(lambda x: len(x.split()))\n",
    "\n",
    "bbc_data_copy.groupby('labels')['doc_length'].mean().plot(kind='bar')\n",
    "plt.ylabel('Average number of words')\n",
    "plt.title('Average number of words in each document per label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot of the number of words in each document per label\n",
    "\n",
    "sns.boxplot(x='doc_length', y='labels', data=bbc_data_copy)\n",
    "plt.ylabel('Number of words')\n",
    "plt.title('Number of words in each document per label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Interestingly, the two shortest labels by document word count are sports and entertainment, with business close beind and the topics of politics and tech taking much longer. Each topic has outliers in both length and words used.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split and preprocess data\n",
    "\n",
    "X = bbc_data['data'].apply(gensim.utils.simple_preprocess)\n",
    "y = bbc_data['labels']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat386",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
